# Relatório Final

## Descrição do Problema

O problema abordado no projeto do módulo 9 "Aprendizado por reforço para aplicação com Redes Neurais Artificiais" centrou-se na complexidade e nos desafios associados à precificação diária de ativos sintéticos de renda fixa no mercado financeiro contemporâneo. Esses ativos, caracterizados por sua natureza intrincada, exigem uma abordagem cuidadosa para a precificação, a fim de equalizar a rentabilidade em torno de 100% do CDI (Certificado de Depósito Interbancário), que é um indicador significativo de desempenho no mercado financeiro brasileiro. A principal dificuldade residia na busca por combinações ideais de negociações à vista de ações que correspondessem aos contratos a termo, visando alcançar a rentabilidade desejada. Além disso, a necessidade de minimizar a intervenção manual e garantir a assertividade nos preços adicionava camadas de complexidade ao problema. Esses ativos sintéticos de renda fixa, que frequentemente envolvem derivativos complexos ou estratégias de hedge, apresentam desafios únicos em termos de liquidez e volatilidade, influenciando diretamente a estabilidade financeira e a confiança dos investidores. Esse desafio foi proposto pela área de fundos de investimento do BTG Pactual, com o objetivo de encontrar as rentabilidades dos ativos que mais correspondem à realidade.

## Solução Desenvolvida

Para resolver esse desafio, a solução desenvolvida no projeto empregou técnicas de Aprendizagem por Reforço, um paradigma de Inteligência Artificial que permite a um agente aprender a tomar decisões ótimas através da interação com um ambiente. Neste caso, o agente foi projetado para aprender a estratégia ideal de precificação que aproximasse a rentabilidade dos ativos em relação ao CDI. O sistema de Aprendizagem por Reforço foi baseado na ideia de recompensas e penalidades, onde o agente realizava ações de precificação e recebia feedback na forma de recompensas ou punições, ajustando seu comportamento para encontrar a rentabilidade mais real ao longo do tempo. Utilizamos uma rede neural profunda para modelar a política de decisão do agente, treinada através do algoritmo de Deep Q-Network (DQN), que se mostrou particularmente eficaz para lidar com o grande espaço de estados associado às condições de mercado variáveis.

Além da implementação de técnicas de Aprendizagem por Reforço, a solução também incorporou práticas de MLOps (Operações de Aprendizado de Máquina) para garantir a eficiência e a robustez do sistema. Isso incluiu a configuração de integração contínua e implantação automatizada, permitindo a automação de testes, validações, compilação do código e implantação segura da solução no ambiente de produção.

## Resultados Obtidos

Os resultados obtidos pelo projeto foram significativos, demonstrando que a solução desenvolvida conseguiu otimizar a precificação dos ativos de renda fixa de forma a aproximá-los da rentabilidade em torno de 100% do CDI. A aplicação das técnicas de Aprendizagem por Reforço resultou em uma melhoria na assertividade da precificação, reduzindo a necessidade de intervenções manuais e aumentando a eficiência operacional. A validação dos resultados foi realizada através de comparações com benchmarks de mercado e análises retrospectivas, confirmando a eficácia da abordagem adotada.

## Lições Aprendidas

Ao longo do projeto, várias lições foram aprendidas, incluindo a importância da colaboração interdisciplinar entre cientistas de dados, engenheiros de software e especialistas do mercado financeiro. A complexidade dos modelos de Aprendizagem por Reforço exigiu uma compreensão profunda tanto da teoria quanto das implicações práticas, o que reforçou a necessidade de uma abordagem rigorosa na fase de modelagem e testes. Além disso, a implementação de práticas de MLOps demonstrou ser crucial para a manutenção e escalabilidade do sistema em um ambiente de produção real, ensinando a equipe a importância de preparar a infraestrutura tecnológica para suportar operações de aprendizado de máquina em grande escala.